{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2980, 20, 98)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TRAINING_X_FILE = '../../data/feature_vectors/train_x_100d.npy'\n",
    "TRAINING_Y_FILE = '../../data/feature_vectors/train_y_100d.npy'\n",
    "\n",
    "X = np.load(TRAINING_X_FILE)\n",
    "y = np.load(TRAINING_Y_FILE)\n",
    "original_shape = X.shape\n",
    "original_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\didi\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale, minmax_scale\n",
    "X = minmax_scale(X.reshape(-1, X.shape[2]), feature_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2980, 20, 98) (2980,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "\n",
    "def gmm(X, params):\n",
    "    print('GMM...')\n",
    "    transformed = []\n",
    "\n",
    "    for doc in X:\n",
    "        segments_count = len(doc)\n",
    "        multiplier = math.ceil(params['n_components']/segments_count)\n",
    "        doc = np.array(doc).repeat(multiplier, axis=0)\n",
    "\n",
    "        if segments_count < params['n_components']:\n",
    "            print(\"Duplicating segments: \", segments_count, doc.shape)\n",
    "\n",
    "        if params['pca']:\n",
    "            doc = PCA(n_components=50).fit_transform(doc)\n",
    "\n",
    "        n_components = np.arange(1, params['n_components'] + 1)\n",
    "        models = [\n",
    "            GaussianMixture(\n",
    "                n, covariance_type=params['covariance_type'], random_state=0, verbose=0)\n",
    "            .fit(doc) for n in n_components\n",
    "        ]\n",
    "\n",
    "        transformed.append([m.bic(doc) for m in models])\n",
    "    \n",
    "    return np.array(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM...\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'pca': False,\n",
    "    'n_components': 3,\n",
    "    'covariance_type': 'spherical'\n",
    "}\n",
    "X = gmm(X, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2980, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6057046979865772"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "params={\n",
    "    'rf_params': {\n",
    "                'n_estimators': 300,\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1,\n",
    "                'verbose': 0\n",
    "            },\n",
    "    'ab_params': {\n",
    "                'n_estimators': 300,\n",
    "                'random_state': 42,\n",
    "            },\n",
    "}\n",
    "clf = RandomForestClassifier(**params['rf_params']).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59395973 0.5704698  0.5738255  0.65771812 0.60738255]\n",
      "0.6006711409395973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
